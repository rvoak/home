

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- Here are the current paper tags:
1) tag-all (for all papers)
2) tag-privacy
3) tag-host-security
4) tag-network-security
5) tag-theoretical-foundations


-->
<html><head>
<title>Security for Artificial Intelligence</title>
<style type="text/css">
body {
    margin-top: 30px;
    margin-bottom: 30px;
    margin-left: 100px;
    margin-right: 100px;
}
p {
    margin-top: 0px;
    margin-bottom: 0px;
}

.caption {
    font-size: 34px;
    font-weight: normal;
    color: #000;
    font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #990000;
}
.caption-3 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #F00;
}

.caption-4 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
}
.content {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    text-align: justify;
}

.title-small {
    font-size: 20px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #F90;
}
.title-large {
    font-size: 28px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #000;
}
.margin {
    font-size: 10px;
    line-height: 10px;
}
.margin-small {
    font-size: 5px;
    line-height: 5px;
}
.margin-large {
    font-size: 16px;
    line-height: 16px;
}
</style>
<script type="text/javascript" src="jquery.js"></script>     
<script type="text/javascript"> 

function displaypage(){
	$(".tag-all").hide();
	if(document.getElementById('tag-all-box').checked){
		$(".tag-all").show();
	}
	if(document.getElementById('tag-theoretical-foundations-box').checked){
		$(".tag-theoretical-foundations").show();
	}
	if(document.getElementById('tag-host-security-box').checked){
		$(".tag-host-security").show();
	}
	if(document.getElementById('tag-network-security-box').checked){
		$(".tag-network-security").show();
	}
	if(document.getElementById('tag-privacy-box').checked){
		$(".tag-privacy").show();
	}

}

$(document).ready(function() {    

$("#tag-all-box").click(function() {
	displaypage();
});   
$("#tag-theoretical-foundations-box").click(function() {
	displaypage();
});
$("#tag-host-security-box").click(function() {
	displaypage();
}); 
$("#tag-network-security-box").click(function() {
	displaypage();
}); 
$("#tag-privacy-box").click(function() {
	displaypage();
}); 

});             
</script>     
<meta content="text/html; charset=unicode" http-equiv="Content-Type">
<meta name="GENERATOR" content="MSHTML 9.00.8112.16443"></head>
<body><center><h1><span>Security for Artificial Intelligence</span></h1></center>

<center>
		[<a href="#statement">Research Statement</a>] [<a href ="#publications">Publications</a>]  [<a  href="https://aisecure.github.io/HOME/">Home</a>]
    <!-- [<a href="#members">Members</a>]   -->
</center>

<h2 class="label"><a name="statement"><span >Research Statement</span></a></h2> 
As intelligent systems become pervasive, safeguarding their security and privacy is critical. For example, adversarially manipulating the perceptual systems of autonomous vehicles may lead to misreading road signs, with possibly catastrophic consequences.
The goal of this project is to design efficient learning systems resilient against sophisticated adversarial manipulations in real-world applications.


<br><br>
Towards this goal, we focus on adversarial learning, an interdisciplinary
field at the intersection of machine learning, security, privacy, and game theory. Special emphasis is placed on understanding the weaknesses of learning systems theoretically and empirically by exploring novel attack strategies, game-theoretic modeling of the dynamics between intelligent adversaries and learning systems, and applying security expertise to 
strengthen learning systems.



 
<hr>

<h2 class="label"><a name="publications"><span >Recent Publications</span></a></h2>

<!--<form> 
  <div id="tags"> 
    <input type="radio" name="tags" checked id="tag-all-box"> 
    <label for="tag-all-box">All Publications</label> 
   
    <input type="radio" name="tags" id="tag-theoretical-foundations-box"> 
    <label for="tag-theoretical-foundations-box">Theoretical Foundations</label>
 
    <input type="radio" name="tags" id="tag-host-security-box">
    <label for="tag-host-security-box">Host Security</label> 
    
    <input type="radio" name="tags" id="tag-network-security-box"> 
    <label for="tag-network-security-box">Network Security</label> 
    
    <input type="radio" name="tags" id="tag-privacy-box"> 
    <label for="tag-privacy-box">Privacy</label> 
    
  </div> 
</form> -->
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/RoG.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1901.11300"><strong>Robust Inference via Generative Classifiers for Handling Noisy Labels</strong></a></p>
      <p class="content">Kimin Lee, Sukmin Yun, Kibok Lee, Honglak Lee, Bo Li, Jinwoo Shin.</p>
      <p class="content">ICML 2019</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/MeshAdv.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1810.05206"><strong>Realistic Adversarial Examples in 3D Meshes</strong></a></p>
      <p class="content">Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, Mingyan Liu.</p>
      <p class="content">CVPR 2019 [oral]</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/3d_adv_point_cloud.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1809.07016"><strong>Generating 3D Adversarial Point Clouds</strong></a></p>
      <p class="content">​Chong Xiang, Charles R. Qi, Bo Li.</p>
      <p class="content">CVPR 2019 </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/TextBugger.png" border="1"width="210"></a></td> 
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1812.05271"><strong>TextBugger: Generating Adversarial Text Against Real-world Applications</strong></a></p>
      <p class="content">​Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, Ting Wang.</p>
      <p class="content">NDSS 2019 </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/DeepSpec.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://www.semanticscholar.org/paper/DEEPSEC%3A-A-Uniform-Platform-for-Security-Analysis-Ling-Ji/fda5f4facce9d5567c090d7ac733158e0fe93dc7"><strong>DeepSec: A Uniform Platform for Security Analysis of Deep Learning Models</strong></a></p>
      <p class="content">​Xiang Ling, Shouling Ji, Jiaxu Zou, Jiannan Wang, Chunming Wu, Bo Li, Ting Wang.</p>
      <p class="content">Oakland 2019 </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/Fig_TD_demo.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1809.10875"><strong>Characterizing Audio Adversarial Examples Using Temporal Dependency</strong></a></p>
      <p class="content">Zhuolin Yang, Bo Li, Pin-Yu Chen, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (ICLR). May, 2019.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/DeepGauge.png" border="1"width="210"></a></td> 
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1803.07519"><strong>DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems</strong></a></p>
      <p class="content">​Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, and Yadong Wang.</p>
      <p class="content">ASE 2018 [Distinguished Paper Award] </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>
<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/manipulating_ml.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1804.00308"><strong>Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning</strong></a></p>
      <p class="content">​Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, Bo Li.</p>
      <p class="content">Oakland 2018 </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/poison_learning_in_game.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://ruoxijia.github.io/assets/papers/IoT_poisoning.pdf"><strong>Poisoning Attacks on Data-Driven Utility Learning in Games</strong></a></p>
      <p class="content">​Ruoxi Jia, Ioannis Konstantakopoulos, Bo Li, Dawn Song, Costas J. Spanos. </p>
      <p class="content">ACC 2018  </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>




<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/segmentation-eccv.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1810.05162"><strong>Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation</strong></a></p>
      <p class="content">Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, Mingyan Liu, Dawn Song.</p>
      <p class="content">The European Conference on Computer Vision (ECCV), September, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/blackbox-eccv.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1712.09491"><strong>Exploring the Space of Black-box Attacks on Deep Neural Networks</strong></a></p>
      <p class="content">Arjun Nitin Bhagoji, Warren He, Bo Li, Dawn Song.</p>
      <p class="content">The European Conference on Computer Vision (ECCV), September, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>


<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/advGAN.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1801.02610"><strong>Generating Adversarial Examples with Adversarial Networks</strong></a></p>
      <p class="content">Chaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, Dawn Song.</p>
      <p class="content">The International Joint Conference on Artificial Intelligence (IJCAI), July, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>


<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/stopsign.jpg" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1707.08945"><strong>Robust Physical-World Attacks on Deep Learning Visual Classification</strong></a></p>
      <p class="content">Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul Prakash, Amir Rahmati, Chaowei Xiao, Dawn Song.</p>
      <p class="content">The Conference on Computer Vision and Pattern Recognition (CVPR). June, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      <p class="content">
        Press: <a href="https://spectrum.ieee.org/cars-that-think/transportation/sensors/slight-street-sign-modifications-can-fool-machine-learning-algorithms">IEEE Spectrum</a> | <a href="https://sg.news.yahoo.com/researchers-demonstrate-limits-driverless-car-technology-151138885.html">Yahoo News</a> | <a href="https://www.wired.com/story/security-news-august-5-2017">Wired</a> | <a href="https://www.engadget.com/2017/08/06/altered-street-signs-confuse-self-driving-cars/">Engagdet</a> | <a href="http://www.telegraph.co.uk/technology/2017/08/07/graffiti-road-signs-could-trick-driverless-cars-driving-dangerously/">Telegraph</a> | <a href="http://blog.caranddriver.com/researchers-find-a-malicious-way-to-meddle-with-autonomous-cars/">Car and Driver</a> | <a href="https://www.cnet.com/roadshow/news/it-is-surprisingly-easy-to-bamboozle-a-self-driving-car/">CNET</a> | <a href="https://www.digitaltrends.com/cars/self-driving-cars-confuse-stickers-signs/">Digital Trends</a> | <a href="https://www.scmagazine.com/subtle-manipulation-of-street-signs-can-fool-self-driving-cars-researchers-report/article/680146/">SCMagazine</a> | <a href="https://www.schneier.com/blog/archives/2017/08/confusing_self-.html">Schneier on Security</a> | <a href="https://arstechnica.com/cars/2017/09/hacking-street-signs-with-stickers-could-confuse-self-driving-cars/?amp=1">Ars Technica</a> | <a href="http://fortune.com/2017/09/02/researchers-show-how-simple-stickers-could-trick-self-driving-cars/">Fortune</a> | <a href="http://www.sciencemag.org/news/2018/07/turtle-or-rifle-hackers-easily-fool-ais-seeing-wrong-thing">Science Magazine</a>
      </p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/advSubspace.png" border="1"width="210"></a></td> 
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1801.02613"><strong>Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality</strong></a></p>
      <p class="content">Xingjun Ma, Bo Li, Yisen Wang, Sarah M. Erfani, Sudanthi Wijewickrema, Michael E. Houle, Grant Schoenebeck, Dawn Song, James Bailey.</p>
      <p class="content">International Conference on Learning Representations (ICLR). May, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/spAdv.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1801.02612"><strong>Spatially Transformed Adversarial Examples
</strong></a></p>
      <p class="content">Chaowei Xiao*, Jun-Yan Zhu*, Bo Li, Mingyan Liu, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (ICLR). May, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/decisionBoundary.png" border="1"width="210"></a></td> 
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://openreview.net/forum?id=BkpiPMbA-&noteId=BkpiPMbA-"><strong>Decision Boundary Analysis of Adversarial Examples</strong></a></p>
      <p class="content">Warren He, Bo Li, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (ICLR). May, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>



<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/robust_linear_reg.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="http://vorobeychik.com/2017/poisonlr.pdf"><strong>Robust Linear Regression Against Training Data Poisoning</strong></a></p>
      <p class="content">Chang Liu, Bo Li, Yevgeniy Vorobeychik, and Alina Oprea.</p>
      <p class="content">AISec 2017. [Best Paper Award]</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>


<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/singleton_clf.png" border="1"width="210"></a></td> 
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="http://vorobeychik.com/2017/largeScaleDetection.pdf"><strong>Large-scale identification of malicious singleton files</strong></a></p>
      <p class="content">B. Li, K. Roundy, C. Gates and Y. Vorobeychik.</p>
      <p class="content"> In ACM Conference on Data and Application Security and Privacy (CODASPY 2017). </p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="files/backdoorPoisoning.jpg" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1712.05526"><strong>Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning</strong></a></p>
      <p class="content">Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song.</p>
      <p class="content">December, 2017.</p>
     <p class="margin-small">&nbsp;</p>
      <p class="content">
        Press: <a href="https://motherboard.vice.com/en_us/article/yw5dng/how-to-turn-a-pair-of-glasses-into-an-ai-fooling-spy-tool">Motherboard</a> | <a href="https://www.theregister.co.uk/2017/12/20/fool_ai_facial_recognition_poison/">The Register</a>
      </p>
      </tr>
</tbody></table>




<!-- 
<hr>



<h2 class="label"><a name="members"><span >Members</span></a></h2>

<ul>
  <li><p class="content"><b>Faculty</b></p><ul>

    <li><p class="content"><a href="http://www.crystal-boli.com/">Bo Li</a> (UIUC)</p></li>
  </ul><br></li>
  
  <li><p class="content"><b>Ph.D. Students:</b></p>
  <ul>
    <li><p class="content"><a href="https://jungyhuk.github.io/">Xinyun Chen</a></p></li>
    <li><p class="content"><a href="https://people.eecs.berkeley.edu/~ricshin/">Richard Shin</a></p></li>
    <li><p class="content">Warren He</p></li>
  </ul>
  <br>
  </li>

  <li><p class="content"><b>Others:</b></p>
 <ul>
   <li><p class="content"> <a href=""></a>(NUS)</p> </li>
  </ul><br>
  </li>
</li>
</ul> -->
<br><br></body></html>
